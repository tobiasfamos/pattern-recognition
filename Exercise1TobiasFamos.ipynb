{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# First Exercise for Pattern Recognition\n",
    "\n",
    "**Goal:** Implement a KNN (K nearest neighbour) classification algorithm from scratch\n",
    "\n",
    "## Overview of the approach\n",
    "1. Read the data from the MNIST Dataset\n",
    "2. Write KNN Classification Algorithm\n",
    "4. Run the classification function over the train set to parametrise the mode\n",
    "5. Test the outcome with the test set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Import needed packages"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "import numpy\n",
    "import time\n",
    "from scipy import spatial\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define Reading function for file paths"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readMnistData(filePath):\n",
    "    return numpy.genfromtxt(filePath, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def getClassification(mnistDataEntry: numpy.ndarray):\n",
    "    return mnistDataEntry[0]\n",
    "\n",
    "def getMnistData(mnistDataEntry: numpy.ndarray):\n",
    "    return numpy.delete(mnistDataEntry, [0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Euclidean Distance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def euclideanDistance(vectorA: numpy.ndarray, vectorB: numpy.ndarray):\n",
    "    return numpy.sum(numpy.sqrt(numpy.power(vectorA - vectorB, 2)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Manhattan Distance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def manhattanDistance(vectorA: numpy.ndarray, vectorB: numpy.ndarray):\n",
    "    return numpy.sum(numpy.abs(vectorA - vectorB))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Read the train file"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "trainData = readMnistData(\"train.csv\")\n",
    "testData = readMnistData(\"test.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "First try to brute force one classification"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Brute force Iterative\n",
    "Here follows the first try with just a brute force approach with no optimizations. The programm runs extremely slow. I would not recommend to let it run through."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "def bruteforce1nn(toClassify: numpy.ndarray, trainSet: numpy.ndarray):\n",
    "    withoutClassification = getMnistData(toClassify)\n",
    "    smallestDistance = 100000\n",
    "    bestCurrentClassifier = -1\n",
    "    for currentIndex in range(0, len(trainSet)):\n",
    "        currentTrainData = testData[currentIndex]\n",
    "        currentDistance = euclideanDistance(getMnistData(currentTrainData), withoutClassification)\n",
    "        if smallestDistance > currentDistance:\n",
    "            smallestDistance = currentDistance\n",
    "            bestCurrentClassifier = getClassification(currentTrainData)\n",
    "    return bestCurrentClassifier\n",
    "\n",
    "\n",
    "def checkClassification(classification, toClassify: numpy.ndarray):\n",
    "    return classification == getClassification(toClassify)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "def getTimeApproxPerClassification(functionToTime, trainDataSetToUse):\n",
    "    start = time.time()\n",
    "    for index, currentDataSet in enumerate(testData):\n",
    "        functionToTime(currentDataSet, trainDataSetToUse)\n",
    "        print(index)\n",
    "    end = time.time()\n",
    "    print(end - start)\n",
    "    return (end - start)/100"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "getTimeApproxPerClassification(bruteforce1nn, testData)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "correct = 0\n",
    "false = 0\n",
    "print(\"Total number of Test cases: \"+ str(len(testData)))\n",
    "\n",
    "for index, currentDataSet in enumerate(testData):\n",
    "    classifiedAs = bruteforce1nn(currentDataSet, trainData)\n",
    "    if classifiedAs == getClassification(currentDataSet):\n",
    "        correct += 1\n",
    "    else:\n",
    "        false += 1\n",
    "    print(str(index) + \": c: \" + str(correct) + \" f: \" + str(false))\n",
    "\n",
    "accuracy = correct / len(testData)\n",
    "print(\"Correct Classified: \" + str(correct))\n",
    "print(\"False Classified: \" + str(false))\n",
    "\n",
    "print(\"Accuracy: \" + str(accuracy))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Next Approach: Don't calculate iteratively but use pre build optimized spacial package.\n",
    "As the above appproach would take ages to run through all the 50'000 entries I decided to move to the scipy.spacial.distance functionality. It is quite optimized and thus takes less time all in all."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def getDistanceMatrix(testData, trainData, metric):\n",
    "    return  spatial.distance.cdist(getOnlyData(testData), getOnlyData(trainData), metric=metric)\n",
    "\n",
    "def getMostOccurringElement(row: numpy.ndarray):\n",
    "    values, counts = numpy.unique(row, return_counts=True)\n",
    "    return values[numpy.argmax(counts)]\n",
    "\n",
    "\n",
    "def getAllClassifications(dataMatrix: numpy.matrix):\n",
    "    return numpy.squeeze(numpy.asarray(dataMatrix[:,0]))\n",
    "\n",
    "def getOnlyData(dataMatrix: numpy.matrix):\n",
    "    return numpy.asarray(dataMatrix[:,1:])\n",
    "\n",
    "\n",
    "def getKNearestNeightbourIndices(distanceMatrix: numpy.ndarray, k):\n",
    "    kNearestNeighbours = numpy.argpartition(distanceMatrix,k)[:,:k]\n",
    "    return numpy.squeeze(numpy.asarray(kNearestNeighbours))\n",
    "\n",
    "def performKNearestNeighbour(distances, trainDataToUse, testDataToUse, k):\n",
    "    nearestNeighbourIndices = getKNearestNeightbourIndices(distances, k)\n",
    "    allPredictions = getAllClassifications(trainDataToUse)[nearestNeighbourIndices]\n",
    "    if len(numpy.shape(allPredictions)) > 1:\n",
    "        predictions = numpy.apply_along_axis(lambda v: getMostOccurringElement(v), axis=1, arr=allPredictions)\n",
    "        return predictions\n",
    "    else:\n",
    "        return allPredictions\n",
    "\n",
    "def getCorrectness(madeClassifications, trueClassifications):\n",
    "    subtractedClassifications = numpy.subtract(trueClassifications, madeClassifications)\n",
    "    numberOfFalse = numpy.count_nonzero(subtractedClassifications)\n",
    "    return 1 - numberOfFalse / len(trueClassifications)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "euclideanDistanceMatrix = getDistanceMatrix(testData, trainData, 'euclid')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "manhattanDistanceMatrix = getDistanceMatrix(testData, trainData, 'cityblock')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Euclid\n",
      "| 1 | 0.965|\n",
      "| 3 | 0.964|\n",
      "| 5 | 0.964|\n",
      "| 10 | 0.96|\n",
      "| 15 | 0.956|\n",
      "And for Manhattan\n",
      "| 1 | 0.957|\n",
      "| 3 | 0.957|\n",
      "| 5 | 0.957|\n",
      "| 10 | 0.952|\n",
      "| 15 | 0.946|\n"
     ]
    }
   ],
   "source": [
    "def performNKNNClassifications(ks: numpy.ndarray, distanceMatrix, trainData, testData):\n",
    "    for k in ks:\n",
    "        predictedClass = performKNearestNeighbour(distanceMatrix, trainData, testData, k)\n",
    "        accuracy = getCorrectness(predictedClass, getAllClassifications(testData))\n",
    "        print(f\"| {k} | {round(accuracy, 3)}|\")\n",
    "\n",
    "ks = numpy.array([1, 3, 5, 10, 15])\n",
    "print(\"Accuracy for Euclid\")\n",
    "performNKNNClassifications(ks, euclideanDistanceMatrix, trainData, testData)\n",
    "print(\"And for Manhattan\")\n",
    "performNKNNClassifications(ks, manhattanDistanceMatrix, trainData, testData)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Accuracies for euclidean Distance\n",
    "The Accuracies stay pretty much the same with a slight decline with higher ks\n",
    "\n",
    "| k   | accuracy |\n",
    "|-----|----------|\n",
    "| 1   | 0.964    |\n",
    "| 3   | 0.964    |\n",
    "| 5   | 0.963    |\n",
    "| 10  | 0.960    |\n",
    "| 15  | 0.955    |\n",
    "\n",
    "# Accuracies for Manhattan Distance\n",
    "They behave quite like the euclidean\n",
    "\n",
    "| k   | accuracy |\n",
    "|-----|----------|\n",
    "| 1 | 0.957|\n",
    "| 3 | 0.957|\n",
    "| 5 | 0.957|\n",
    "| 10 | 0.952|\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}